<!DOCTYPE HTML>
<!--
	Spectral by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Ana Maria Sousa | AI Engineer</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="stylesheet" href="assets/css/pub_style.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Page Wrapper -->
			<div id="page-wrapper">

				<!-- Header -->
					<header id="header">
						<h1><a href="index.html">Ana Sousa</a></h1>
						<nav id="nav">
							<ul>
								<li class="special">
									<a href="#menu" class="menuToggle"><span>Menu</span></a>
									<div id="menu">
										<ul>
											<li><a href="index.html">Home</a></li>
											<li><a href="academic&career.html">Work Experience</a></li>
											<li><a href="academic&career.html">Education</a></li>
											<li><a href="proj&pub.html">Projects & Publications</a></li>
											<!--<li><a href="elements.html">Elements</a></li>-->

											<li><a href="index.html#awards">Awards</a></li>
											<li><a href="index.html#tech_skills">Tech skills & tools</a></li>
											<li><a href="index.html#three">Interests & Hobbies</a></li>
											<li><a href="index.html#lang">Languages</a></li>
										</ul>
									</div>
								</li>
							</ul>
						</nav>
					</header>

				<!-- Main -->
					<article id="main">
									
							
						<header>
							<h2> Publications </h2>
						</header>

						<section class="wrapper style5">
							<div class="inner">
								<h4 class="title">Learning to write medical reports from EEG data</h4>
								<figure>
									<img class="paper-img" src="images/thesis_img.jpg" alt="EEG Data">
									<figcaption>Fig 1. What if we could “translate” what the brain is saying? System schema of the research hypotheses</figcaption>
								</figure>
								<div class="description">
									<h6 style="color: #76ddff">
										<a href="https://repositorio-aberto.up.pt/handle/10216/144617">
											Maria Amaro de Sousa, A. (2022). Learning to write medical reports from EEG data. Masters dissertation. Faculty of Engineering of the University of Porto.
										</a>
									</h6>
									<p class="clickable">Electroencephalography (EEG) is an essential tool for the diagnosis and management of epilepsy, one of the most prevalent neurological disorders in the world, characterized by an increased likelihood of seizures. However, these periods of abnormal brain activity (ictal EEG) may not occur often, so the diagnosis is usually made by visual analysis of the EEG in interictal periods. During this analysis, the neurologist summarizes the findings and diagnosis in a clinical report. Although this is a current practice, it entails several disadvantages that motivate the development of automatic auxiliary algorithms that can streamline clinical workflow, reduce subjectivity, and potentially improve diagnosis.<span class="click-indicator"> (Click to read more)</span></p>
									<div class="remaining-content">
										<p>To address these shortcomings in EEG analysis and reporting, we apply DL methods adapting state-of-the-art image and video captioning approaches to generate automated preliminary clinical reports directly from the EEG signal. For that, we develop several captioning architectures. In all of them, a recurrent model is used as a decoder and the encoder is a previously trained convolutional model (VGG16) for classification. Implemented captioning models differ in the aggregation EEG embeddings methods used to extract and summarize the entire recording. This includes EEG average embedding-based, recurrent-based, attention-based, and multi-stream-based methods. The performance of the models was evaluated qualitatively by analyzing the reports and quantitatively by calculating common natural language processing metrics.</p>
										<p>We have shown that it is possible to generate reports from EEG data, but there is still space for improvement. We innovate by designing architectures for EEG captioning based on other architectures that have proven effective in other fields. There is great potential in the use of DL-based methods, but obtaining a model capable of diversifying language, dealing with the diversity of clinical conditions, and generating a report that effectively describes all EEG events are some challenges that must be tackled before implementing in the clinic.</p>
									</div>
								</div>
							</div>

							<div class="wrapper style4 special">
									<p>Member of the  </p>

							</div>


							<div class="inner">
								<h4 class="title">Detection of Interictal epileptiform discharges with semi-supervised deep learning</h4>
								<figure>
									<img class="paper-img" src="images/semi-supervised_epi_detection.jpg" alt="Epileptiform Discharges">
									<figcaption>Fig 2. Graphical summary representing unsupervised and semi-supervised deep learning methods</figcaption>
								</figure>
								<div class="description">
									<h6 style="color: #76ddff">
										<a href="https://doi.org/10.1016/j.bspc.2023.105610">
											Ana Maria Amaro de Sousa, Michel J.A.M. van Putten, Stéphanie van den Berg, Maryam Amir Haeri, Detection of Interictal epileptiform discharges with semi-supervised deep learning, Biomedical Signal Processing and Control, Volume 88, Part B, 2024
										</a>
									</h6>
									<p class="clickable">Interictal discharges (IEDs) in EEG recordings are important signatures of epilepsy as their presence is strongly associated with an increased risk of seizures. IEDs are relatively short-duration events (typically 70-250 ms) that can be viewed as stochastic anomalies in such recordings. Currently, visual analysis of the EEG by clinical experts is the gold standard. This process, however, is time-consuming, error-prone, and associated with a long learning period.<span class="click-indicator"> (Click to read more)</span></p>
									<div class="remaining-content">
										<p>Automating the detection of IEDs has the potential to significantly reduce review time and may serve to complement the visual analysis. Supervised deep learning methods have shown potential for this purpose, but the scarceness of annotated data has limited their performance, which motivates exploring unsupervised and semi-supervised approaches that do not require (extensive) expert annotations.</p>
										<p>We trained different unsupervised deep learning models, Autoencoders (AE), and Variational Autoencoders (VAE) for anomaly (IED) detection in these recordings. Our work shows that unsupervised approaches and other approaches with limited supervision perform satisfactorily and have the potential to assist the visual assessment of interictal discharges in epilepsy diagnostics.</p>
									</div>
								</div>
							</div>
						</section> 
					</article>

				<!-- Footer -->
					<footer id="footer">
						<ul class="icons">
							<li><a href="https://www.facebook.com/profile.php?id=100013202499165" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
							<li><a href="mailto:anamariaas.eng@gmail.com" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
							<li><a href="https://www.linkedin.com/in/ana-maria-sousa-bioeng/" class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
    							<li><a href="https://github.com/AMfeta99" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
						<ul class="copyright">
							<li>&copy 2023, Ana Sousa </li>
						</ul>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
			<script src="assets/js/pub.js"></script>

	</body>
</html>
