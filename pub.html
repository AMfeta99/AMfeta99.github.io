<!DOCTYPE HTML>
<html>

<head>
	<title>Publications | Ana Maria Sousa - AI Engineer</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<meta name="description"
		content="Research publications by Ana Maria Sousa on deep learning, EEG analysis, epilepsy detection, and medical AI applications." />
	<meta name="keywords"
		content="AI research, deep learning, EEG, epilepsy detection, medical AI, semi-supervised learning, neural networks" />
	<meta name="author" content="Ana Maria Sousa" />

	<!-- Open Graph Meta Tags -->
	<meta property="og:title" content="Publications | Ana Maria Sousa - AI Engineer" />
	<meta property="og:description"
		content="Research publications on deep learning, EEG analysis, and medical AI applications." />
	<meta property="og:type" content="website" />

	<!-- Favicon -->
	<link rel="icon" type="image/x-icon" href="favicon.ico" />

	<!-- Google Fonts -->
	<link rel="preconnect" href="https://fonts.googleapis.com">
	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">

	<link rel="stylesheet" href="assets/css/main.css" />
	<link rel="stylesheet" href="assets/css/pub_style.css" />
	<noscript>
		<link rel="stylesheet" href="assets/css/noscript.css" />
	</noscript>
</head>

<body class="is-preload">

	<!-- Page Wrapper -->
	<div id="page-wrapper">

		<!-- Header -->
		<header id="header">
			<h1><a href="index.html">Ana Sousa</a></h1>
			<nav id="nav">
				<ul>
					<li class="special">
						<a href="#menu" class="menuToggle"><span>Menu</span></a>
						<div id="menu">
							<ul>
								<li><a href="index.html">Home</a></li>

								<li><a href="me.html">About Me</a>
									<ul>
										<li><a href="me.html">Who Am I?</a></li>
										<li><a href="me.html#chatgpt_imp">ChatGPT Impression</a></li>
										<li><a href="me.html#three">Interests & Hobbies</a></li>
										<li><a href="me.html#volunteer">Volunteer</a></li>
										<li><a href="me.html#student">Student Groups</a></li>

									</ul>
								</li>
								<li>
									<a href="academic&career.html">Experience/Career</a>
									<ul>
										<li><a href="academic&career.html">AI Experience</a></li>
										<li><a href="academic&career.html#path_img">Work Experience</a></li>
										<li><a href="academic&career.html#edu">Education</a></li>
										<li><a href="academic&career.html#certificates">Certifications & Courses</a>
										</li>
										<li><a href="academic&career.html#cv">Resume (CV)</a></li>

									</ul>
								</li>
								<li><a href="proj.html">Projects</a></li>
								<li><a href="pub.html">Publications</a></li>
								<li><a href="#footer">Contacts</a></li>
								<li>
									<a>Other Links</a>
									<ul>
										<li><a href="index.html#awards">Awards</a></li>
										<li><a href="index.html#tech_skills">Tech skills & tools</a></li>
										<li><a href="index.html#lang">Languages</a></li>
									</ul>
								</li>
							</ul>
						</div>
					</li>
				</ul>
			</nav>
		</header>

		<!-- Main -->
		<article id="main">
			<header class="publications-header">
				<h2>Publications</h2>
				<p class="subtitle">Research contributions in AI, deep learning, and medical signal processing</p>
			</header>

			<section class="wrapper style5">
				<div class="publications-container">

					<!-- Publication Card 1 -->
					<article class="publication-card">
						<div class="card-content">
							<div class="card-header">
								<span class="publication-badge">Journal Article</span>
								<span class="publication-year">2024</span>
							</div>

							<h3 class="publication-title">Detection of Interictal epileptiform discharges with
								semi-supervised deep learning</h3>

							<figure class="publication-figure">
								<img class="paper-img" src="images/semi-supervised_epi_detection.jpg"
									alt="Graphical summary of unsupervised and semi-supervised deep learning methods for epileptiform discharge detection">
								<figcaption>Graphical summary representing unsupervised and semi-supervised deep
									learning methods</figcaption>
							</figure>

							<div class="publication-meta">
								<a href="https://doi.org/10.1016/j.bspc.2023.105610" class="publication-link"
									target="_blank" rel="noopener noreferrer">
									<svg class="link-icon" xmlns="http://www.w3.org/2000/svg" width="16" height="16"
										viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
										stroke-linecap="round" stroke-linejoin="round">
										<path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path>
										<polyline points="15 3 21 3 21 9"></polyline>
										<line x1="10" y1="14" x2="21" y2="3"></line>
									</svg>
									Ana Maria Amaro de Sousa, Michel J.A.M. van Putten, St√©phanie van den Berg, Maryam
									Amir Haeri
								</a>
								<p class="journal-info">Biomedical Signal Processing and Control, Volume 88, Part B,
									2024</p>
							</div>

							<div class="publication-abstract">
								<p>Interictal discharges (IEDs) in EEG recordings are important signatures of epilepsy
									as their presence is strongly associated with an increased risk of seizures. IEDs
									are relatively short-duration events (typically 70-250 ms) that can be viewed as
									stochastic anomalies in such recordings. Currently, visual analysis of the EEG by
									clinical experts is the gold standard. This process, however, is time-consuming,
									error-prone, and associated with a long learning period.</p>

								<div class="expandable-content">
									<p>Automating the detection of IEDs has the potential to significantly reduce review
										time and may serve to complement the visual analysis. Supervised deep learning
										methods have shown potential for this purpose, but the scarceness of annotated
										data has limited their performance, which motivates exploring unsupervised and
										semi-supervised approaches that do not require (extensive) expert annotations.
									</p>
									<p>We trained different unsupervised deep learning models, Autoencoders (AE), and
										Variational Autoencoders (VAE) for anomaly (IED) detection in these recordings.
										Our work shows that unsupervised approaches and other approaches with limited
										supervision perform satisfactorily and have the potential to assist the visual
										assessment of interictal discharges in epilepsy diagnostics.</p>
								</div>

								<button class="read-more-btn" aria-label="Read more about this publication">
									<span class="btn-text">Read more</span>
									<svg class="chevron-icon" xmlns="http://www.w3.org/2000/svg" width="16" height="16"
										viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
										stroke-linecap="round" stroke-linejoin="round">
										<polyline points="6 9 12 15 18 9"></polyline>
									</svg>
								</button>
							</div>

							<div class="publication-tags">
								<span class="tag">Deep Learning</span>
								<span class="tag">EEG Analysis</span>
								<span class="tag">Epilepsy Detection</span>
								<span class="tag">Semi-Supervised Learning</span>
							</div>
						</div>
					</article>

					<!-- Publication Card 2 -->
					<article class="publication-card">
						<div class="card-content">
							<div class="card-header">
								<span class="publication-badge">Master's Thesis</span>
								<span class="publication-year">2022</span>
							</div>

							<h3 class="publication-title">Learning to write medical reports from EEG data</h3>

							<figure class="publication-figure">
								<img class="paper-img" src="images/thesis_img.jpg"
									alt="System schema showing translation of brain signals to medical reports">
								<figcaption>What if we could "translate" what the brain is saying? System schema of the
									research hypotheses</figcaption>
							</figure>

							<div class="publication-meta">
								<a href="https://repositorio-aberto.up.pt/handle/10216/144617" class="publication-link"
									target="_blank" rel="noopener noreferrer">
									<svg class="link-icon" xmlns="http://www.w3.org/2000/svg" width="16" height="16"
										viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
										stroke-linecap="round" stroke-linejoin="round">
										<path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path>
										<polyline points="15 3 21 3 21 9"></polyline>
										<line x1="10" y1="14" x2="21" y2="3"></line>
									</svg>
									Maria Amaro de Sousa, A.
								</a>
								<p class="journal-info">Faculty of Engineering of the University of Porto, Masters
									Dissertation</p>
							</div>

							<div class="publication-abstract">
								<p>Electroencephalography (EEG) is an essential tool for the diagnosis and management of
									epilepsy, one of the most prevalent neurological disorders in the world,
									characterized by an increased likelihood of seizures. However, these periods of
									abnormal brain activity (ictal EEG) may not occur often, so the diagnosis is usually
									made by visual analysis of the EEG in interictal periods. During this analysis, the
									neurologist summarizes the findings and diagnosis in a clinical report. Although
									this is a current practice, it entails several disadvantages that motivate the
									development of automatic auxiliary algorithms that can streamline clinical workflow,
									reduce subjectivity, and potentially improve diagnosis.</p>

								<div class="expandable-content">
									<p>To address these shortcomings in EEG analysis and reporting, we apply DL methods
										adapting state-of-the-art image and video captioning approaches to generate
										automated preliminary clinical reports directly from the EEG signal. For that,
										we develop several captioning architectures. In all of them, a recurrent model
										is used as a decoder and the encoder is a previously trained convolutional model
										(VGG16) for classification. Implemented captioning models differ in the
										aggregation EEG embeddings methods used to extract and summarize the entire
										recording. This includes EEG average embedding-based, recurrent-based,
										attention-based, and multi-stream-based methods. The performance of the models
										was evaluated qualitatively by analyzing the reports and quantitatively by
										calculating common natural language processing metrics.</p>
									<p>We have shown that it is possible to generate reports from EEG data, but there is
										still space for improvement. We innovate by designing architectures for EEG
										captioning based on other architectures that have proven effective in other
										fields. There is great potential in the use of DL-based methods, but obtaining a
										model capable of diversifying language, dealing with the diversity of clinical
										conditions, and generating a report that effectively describes all EEG events
										are some challenges that must be tackled before implementing in the clinic.</p>
								</div>

								<button class="read-more-btn" aria-label="Read more about this publication">
									<span class="btn-text">Read more</span>
									<svg class="chevron-icon" xmlns="http://www.w3.org/2000/svg" width="16" height="16"
										viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
										stroke-linecap="round" stroke-linejoin="round">
										<polyline points="6 9 12 15 18 9"></polyline>
									</svg>
								</button>
							</div>

							<div class="publication-tags">
								<span class="tag">Natural Language Processing</span>
								<span class="tag">Medical AI</span>
								<span class="tag">EEG Analysis</span>
								<span class="tag">Report Generation</span>
							</div>
						</div>
					</article>

				</div>
			</section>
		</article>

		<!-- Footer -->
		<footer id="footer">
			<ul class="icons">
				<li><a href="mailto:anamariaas.eng@gmail.com" class="icon solid fa-envelope"><span
							class="label">Email</span></a></li>
				<li><a href="https://www.linkedin.com/in/ana-maria-sousa-bioeng/"
						class="icon brands fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
				<li><a href="https://github.com/AMfeta99" class="icon brands fa-github"><span
							class="label">GitHub</span></a></li>
			</ul>
			<ul class="copyright">
				<li>&copy 2026, Ana Sousa </li>
			</ul>
		</footer>

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>
	<script src="assets/js/pub.js"></script>

</body>

</html>